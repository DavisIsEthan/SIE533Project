{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "903571e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        fLength    fWidth   fSize   fConc  fConc1     fAsym   fM3Long  \\\n",
      "0       28.7967   16.0021  2.6449  0.3918  0.1982   27.7004   22.0110   \n",
      "1       31.6036   11.7235  2.5185  0.5303  0.3773   26.2722   23.8238   \n",
      "2      162.0520  136.0310  4.0612  0.0374  0.0187  116.7410  -64.8580   \n",
      "3       23.8172    9.5728  2.3385  0.6147  0.3922   27.2107   -6.4633   \n",
      "4       75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277   28.5525   \n",
      "...         ...       ...     ...     ...     ...       ...       ...   \n",
      "19015   21.3846   10.9170  2.6161  0.5857  0.3934   15.2618   11.5245   \n",
      "19016   28.9452    6.7020  2.2672  0.5351  0.2784   37.0816   13.1853   \n",
      "19017   75.4455   47.5305  3.4483  0.1417  0.0549   -9.3561   41.0562   \n",
      "19018  120.5135   76.9018  3.9939  0.0944  0.0683    5.8043  -93.5224   \n",
      "19019  187.1814   53.0014  3.2093  0.2876  0.1539 -167.3125 -168.4558   \n",
      "\n",
      "       fM3Trans   fAlpha     fDist Class  \n",
      "0       -8.2027  40.0920   81.8828     g  \n",
      "1       -9.9574   6.3609  205.2610     g  \n",
      "2      -45.2160  76.9600  256.7880     g  \n",
      "3       -7.1513  10.4490  116.7370     g  \n",
      "4       21.8393   4.6480  356.4620     g  \n",
      "...         ...      ...       ...   ...  \n",
      "19015    2.8766   2.4229  106.8258     h  \n",
      "19016   -2.9632  86.7975  247.4560     h  \n",
      "19017   -9.4662  30.2987  256.5166     h  \n",
      "19018  -63.8389  84.6874  408.3166     h  \n",
      "19019   31.4755  52.7310  272.3174     h  \n",
      "\n",
      "[19020 rows x 11 columns]\n",
      "        fLength    fWidth     fSize     fConc    fConc1     fAsym   fM3Long  \\\n",
      "0     -0.577226 -0.336804 -0.381130  0.062759 -0.148923  0.541042  0.224818   \n",
      "1     -0.510969 -0.570027 -0.648595  0.820383  1.471776  0.516919  0.260364   \n",
      "2      2.568278  6.205858  2.615783 -1.875883 -1.773241  2.044992 -1.478536   \n",
      "3     -0.694768 -0.687259 -1.029478  1.282069  1.606608  0.532771 -0.333515   \n",
      "4      0.516622  0.476384  0.711157 -0.347506 -0.284660 -0.020200  0.353086   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "19015 -0.752189 -0.613988 -0.442072  1.123433  1.617467  0.330947  0.019196   \n",
      "19016 -0.573721 -0.843744 -1.180350  0.846640  0.576817  0.699497  0.051761   \n",
      "19017  0.523923  1.381779  1.318877 -1.305340 -1.445663 -0.084864  0.598262   \n",
      "19018  1.587757  2.982781  2.473375 -1.564081 -1.324404  0.171204 -2.040597   \n",
      "19019  3.161459  1.679993  0.813149 -0.507237 -0.549799 -2.752844 -3.509914   \n",
      "\n",
      "       fM3Trans    fAlpha     fDist Class  \n",
      "0     -0.405842  0.476816 -1.497866     g  \n",
      "1     -0.490094 -0.815418  0.153125     g  \n",
      "2     -2.183030  1.889224  0.842635     g  \n",
      "3     -0.355359 -0.658804 -1.031463     g  \n",
      "4      1.036620 -0.881039  2.176427     g  \n",
      "...         ...       ...       ...   ...  \n",
      "19015  0.126129 -0.966282 -1.164090     h  \n",
      "19016 -0.154268  2.266097  0.717759     h  \n",
      "19017 -0.466509  0.101636  0.839003     h  \n",
      "19018 -3.077206  2.185260  2.870321     h  \n",
      "19019  1.499301  0.961014  1.050442     h  \n",
      "\n",
      "[19020 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "### Import CSV. The original data file lacked column names so we used Excel to insert them. \n",
    "### This will make our lives easier. Also print for a brief sanity check.\n",
    "### NOTE: make sure to change your this inpath and the outpath at the end.\n",
    "inpath = \"C:/Users/Davis/Downloads/magic04data.csv\" \n",
    "data = pd.read_csv(inpath, header=0)\n",
    "print(data)\n",
    "\n",
    "### Now we preprocess the data. Since this dataset was created via simulation, we don't have much to do here as there\n",
    "### are no missing values or NaNs or other issues to clean up. All we need to do is scale the data so it plays nicely \n",
    "### with the machine learning tools we'll use later. We will use sklearn's standard scaler. It's a good tool.\n",
    "\n",
    "### First pop the target column, these are not numbers and sklearn's scaler will get confused\n",
    "target = data.pop(\"Class\")\n",
    "\n",
    "### Retain column names and indexing for later (standard scaler outputs a numpy array which we will transform back to a \n",
    "### pandas dataframe. Having this information will ensure that process performs as expected)\n",
    "column_names = data.columns\n",
    "index = data.index\n",
    "\n",
    "### Scale that data my friends.\n",
    "scaler = preprocessing.StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "### It's that easy. Now put it all back together and do another print sanity check.\n",
    "data = pd.DataFrame(data, index, column_names)\n",
    "data = data.join(target)\n",
    "print(data)\n",
    "\n",
    "### Now I save this to another CSV for easy usage when we build our models. \n",
    "outpath = \"C:/Users/Davis/Downloads/scaledmagicdata.csv\"\n",
    "data.to_csv(outpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
